\chapter{Conclusion}\label{ch:Conclusion}

In this Chapter a summary of the work put forward in this thesis is provided, with the work evaluated against the research aims outlined in Chapter \ref{ch:intro}. Next, potential avenues for future research are explored. 

\section{Thesis Summary}\label{ch:Conclusion,sec:Summary}

Motivated by the problem space as outlined in Chapter \ref{ch:intro}, this thesis explores the use of computer vision and deep learning for the task of automated photo-id catalogue curation and most likely matching. Before beginning work to fulfil the thesis' aims, Chapter \ref{ch:Background} provides the relevant background knowledge required for understanding work described in later Chapters; this includes an introduction to current photo-id methodology, deep learning and computer vision fundamentals, and the current state-of-the-art in photo-id aides. It is here where the problems with current approaches are evaluated in detail, providing further justification for the work undertaken in this thesis. 

In Chapter \ref{ch:cetDet} the first step towards automatic photo-id catalogue management is tackled through the development of a coarse-grain detector capable of generating mask predictions for above water fieldwork imagery, focussing on dolphins as the cetacean species of interest. The environmental and technical requirements of the detector are outlined for use as success metrics, whilst the use of mask predictions rather than bounding boxes is justified. To this end, a Mask R-CNN \cite{he_mask_2017} detector is developed, trained using data  containing examples of Indo-Pacific bottlenose dolphins collected by Newcastle University's Marine MEGAfauna Lab whilst on expedition to Zanzibar, Tanzania in 2015 \cite{sharpe_indian_2019}. 

During model development the use of transfer learning and various data augmentation strategies are explored, helping to mitigate the issues inherent with training deep computer vision models with dataset sizes typical of photo-id surveys. Model hyperparameter optimisation is then performed, before the best performing model on the Zanzibar data is determined. This optimal model achieves high mean average precision (mAP) over a range of key intersection over union (IOU) thresholds confirming coarse-grain detection of cetaceans is possible even in noisy environments and where large variation in the region of interest is present. 

This best model is then utilised to explore the post-processing techniques required to allow for a reduction in the computational expense of downstream models and the removal of unneeded background noise, whilst at the same time ensuring no useful individually identifying markings are lost. The ability to achieve this highlights that it is possible to fully remove the need for the data pre-processing which is currently performed by cetacean researchers, either when performing photo-id matching manually or with the use of aides.

In Chapter \ref{ch:NDD} the developed detector's robustness to species of interest and spatio-temporal changes are evaluated. To achieve this, fieldwork was undertaken alongside Newcastle University's Marine MEGAfauna Lab to create a photo-id catalogue of resident bottlenose and white-beaked dolphins present in the waters around Northumberland, UK, during Summer 2019. Once complete the photo-id catalogue was converted into a dataset useful for computer vision model training, called the Northumberland Dolphin Dataset 2020 (NDD20). Using this data, it can be seen that the detector is capable of high mAP at a range of IOU thresholds, confirming the model is robust to species of interest and spatio-temporal changes. As such, this suggests that no model fine-tuning or re-training is required for use in future photo-id surveys provided the model is trained to a high accuracy using previously obtained imagery. 

Detections from NDD20 are then post-processed to produce a second dataset representative of detector output, allowing for the training of the next model in the pipeline. Additional imagery of the individuals provided by the University of Aberdeen and the University of St Andrews are also included in the identification training dataset, called NDD AU SMRU, as a 23 individual overlap was determined between the catalogue created for Northumberland and those for Eastern Scotland held by the partner institutions. This additional data helps combat the issue of small dataset size when performing model training. 

In Chapter \ref{ch:ID} a model capable of fine-grain, few-shot cetacean re-identification is created, aiding researchers by vastly reducing their search space when performing catalogue matching. Beginning by outlining the requirements this model must adhere to, two possible approaches are evaluated. Through this, the use of a Siamese Neural Network (SNN) based approach is determined most suitable. Model training is performed using two distinct backbone architectures; a relatively simple one called EmbeddingNet and a more complex one known as VarvaraNet based on work by Vetrova \textit{et al.} \cite{vetrova_hidden_2018}. The use of pairwise or triplet ranking losses is explored, as well as online semi-hard triplet mining and hyperparameter tuning via Bayesian optimisation. A range of models were generated, trained using the previously created NDD AU SMRU dataset. Evaluation of the models was performed using top-1, top-5, and top-10 accuracies. The best performing model, a VaravarNet trained without the use of any data augmentation, is capable of vastly reducing the search required by a cetacean researcher when performing most likely catalogue matching. 

The ability of SNNs to allow for the flagging of potentially previously uncatalogued individuals is also explored. Thanks to the model's capability to reduce a high dimensional input down to a low dimensional representation, or embedding, existing catalogue examples can be plotted into a latent space such that they create class clusters. By utilising class prototypes and Euclidean distance measurements, as well as the K-Nearest Neighbours algorithm, this Chapter shows that the flagging of potentially previously unseen individuals can be achieved. Any new individuals which are added to the catalogue can easily be added to the model without the need for re-training thanks to embedding clustering and class prototyping. Further experimentation using a modified version of NDD AU SMRU presents some evidence to suggest that splitting individual classes in two based on which side of the dorsal fin is captured may lead to improved model performance, but further tests may be required to confirm this. 

In Chapter \ref{ch:SNNEvaluation} the robustness of SNNs for the task of most likely catalogue matching is explored. The effects of dataset variation on model performance are quantified, with experimentation suggesting that the retention of background noise through the use of bounding box detections leads to inflated model performance when data has been collected over a small temporal scale. This presents evidence to suggest that the initial decision to perform full background removal through the use of masks was the correct decision, even at the expense of greater computation, and may present an inherent flaw in other photo-id aides which do not remove all background. 

The generalisability of catalogue matching using SNNs is further evaluated through the use of a second photo-id catalogue, provided by the Sarasota Dolphin Research Program. Work here shows that whilst catalogue matching can be performed on other datasets, rather than there being something inherent to the NDD AU SMRU dataset which made this possible, a photo-id catalogue must first exist in order for training to take place. Further, the threshold values utilised in uncatalogued individual thresholding must be tuned. Finally in Chapter \ref{ch:Conclusion}, the work undertaken in this thesis is summarised, its contributions outlined, and avenues for future research explored. 

\section{Evaluation Against Thesis Aims}\label{ch:Conclusion,sec:AimsEvaluation}

As outlined in Chapter \ref{ch:intro}, the aim of this thesis was to \textbf{design, implement, and evaluate a system for fully automatic catalogue matching based on unprocessed photo-id fieldwork imagery}. This was then separated into four research questions (detailed in Section \ref{ch:intro,sec:AimsAndContributions}), each of which should be answered in an attempt to fulfil the overall research aim. 

The first question asks whether it is possible to remove or greatly reduce the need for manual pre-processing of photo-id data in a fully automated way through the use of coarse-grain detection. Work undertaken in Chapter \ref{ch:cetDet} answers this question, proving that it is indeed possible. The model developed during this Chapter is capable of producing highly accurate detections when evaluated using a variety of mAP@IOU thresholds. Through training on unprocessed fieldwork data, the model is able to detect highly variant regions of interest in large-scale, noisy, above water photo-id imagery. When coupled with the developed detection post-processing methodology, the need for manual data pre-processing, such as cropping or rotation, is removed. If pre-processing of photo-id data was required for means other than most likely catalogue matching, or researchers did not wish to pass the data downstream, then the model could be used as a stand-alone system for quickly cropping down fieldwork imagery to only the dorsal fin. 

The second question posits if it is possible to perform detection post-processing in such a way as to both reject likely false positives and remove noise whilst retaining identifiable markings present on the animals. The post-processing methodology outlined in Chapter \ref{ch:cetDet} confirms this is possible. The use of a \textit{dolphin-like} colour threshold, described in Section \ref{ch:cetDet,sec:postProcessing,sub:colourThresholdingMaskComponents} allows for the removal of likely erroneous detections whilst keeping those which are over-exposed but correct, reducing the false-positive retention rate. Further, the inclusion of morphological transformations ensures that any identifying information on the dorsal fin which may have been missed is included in the detection, provided the information is surrounded by pixels which have been correctly classified. Coupled with background removal and cropping, this ensures unneeded noise is removed whilst identifiable markings are retained. 

The third question asks if it is possible to perform highly accurate most likely photo-id catalogue matching based on extreme fine-grain information, even when operating on few-shot data. Work undertaken in Chapter \ref{ch:ID} confirms this can be achieved through the use of a Siamese Neural Network trained using online semi-hard triplet mining. The model is capable of producing sufficiently distinct embeddings for classes within the extreme fine-grain NDD AU SMRU dataset, where there is small inter-class but high intra-class variation. Further, the dataset is also few-shot given the free roaming nature of the individual animals present. High top-1, top-5, and top-10 accuracies are achieved on this dataset, confirming highly accurate automated most likely photo-id catalogue matching is possible. This is further confirmed through evaluation of the approach against the SDRP dataset, where high accuracies are once again obtained. 

Finally, the fourth question asks how generalisable the models created throughout this work are to changes in species of interest and spatio-temporal shifts. In Chapter \ref{ch:cetDet}, the coarse-grain cetacean detector is shown to be highly robust to these changes. High mAP is observed at a range of IOU thresholds on previously unseen photo-id catalogue data collected in a different spatio-temporal area, and containing two new cetacean species, than on that which the model was trained. The approach to most likely catalogue matching is also shown to be generalisable, achieving high accuracies on both the NDD AU SMRU and SDRP datasets in Chapters \ref{ch:ID} and \ref{ch:SNNEvaluation} respectively. However, greater limitations on the generalisability of the catalogue matching model are observed when compared to the dorsal fin detector, as this model requires retraining on the new photo-id catalogue and new thresholds for potentially uncatalogued individual thresholding must be located. 

In summary, as all research questions have been answered it can be stated that the work undertaken in this thesis has achieved its aims. 

\section{Future Research Directions}\label{ch:Conclusion,sec:FutureWork}




