\chapter{Background}\label{ch:Background}

\section{Introduction}\label{ch:Background,sec:Intro}

In recent years, deep learning has become somewhat of a buzzword within the world of computing, and for good reason. Deep learning methods have consistently been shown to outperform other machine learning techniques, especially in the field of computer vision. As the field of deep learning increases in scope every day, this literature review will focus primarily on the world of deep learning in a computer vision context. A brief introduction to deep learning will be provided, before looking at how these methodologies have been applied to computer vision, specifically Convolutional Neural Networks (CNNs) and their use in object detection. Literature focusing on object detection in a marine cetacean space will be explored, as well as the current space of fine-grained computer vision. 

\section{A Brief Introduction to Deep Learning}\label{ch:Background,sec:DLIntro}

Deep learning, a subfield of machine learning, aims to create artificial networks to complete tasks, i.e. learn, in a similar way to how neurons in the human brain operate. These computational models are often multiple neurons deep, known as layers, with lower layers representing basic abstractions, building up from this as you go \textit{deeper} into the network, resulting in final layers of neurons which, based on information passed to them from lower levels, can begin to provide estimations of answers to a given problem. For example in the case of computer vision, lower layers of neurons may be optimised to learn lines and basic shapes, middle layers may be optimised to learn more complex ideas such as how these lines and shapes fit together, with the final layers providing an output of object label (e.g. dog). This is very similar to how the brain learns from the multi-modal data it receives from the body, capturing the intricacies of massive amounts of data using a connection of smaller optimised neurons. 

This ambition to create networks similar to how the brain operates stems mainly from work undertaken in 1943 by McCulloch and Pitts \cite{mcculloch_logical_1943} in an attempt to understand how neurons in the brain allow for the understanding of complex patters. This model formed the basis of future work into machine learning, and thus deep learning. This work continued at small scale for many years. It has only been recently, thanks to advances in availability and power of the computing resources available has deep learning research accelerated. The transition away from model training on CPUs to multiple high-powered GPUs has been one of the largest advancements in deep learning, allowing for a significant speed-up in the train time for these models, resulting in much more prototyping in a smaller time frame. Further to this, the advent of cloud computing has allowed for much more cost-effective model development. Thanks to the Pay As You Go model of computing now commonplace, cloud providers such as Microsoft, Amazon, and Google have eliminated the need for researchers to procure their own hardware required for training, which can in some cases be prohibitively expensive. 

More so, advances in deep learning have been helped greatly through the development of standard development frameworks. Google's Tensorflow \cite{abadi_tensorflow:_2016} and Facebook's PyTorch \cite{paszke_automatic_2017} allow for researchers to develop models much faster than previously due to their reduction in the amount of boiler-plate code needed, with these frameworks often doing a lot of the \textit{heavy lifting} in the background. Further advances have been made through the availability of high quality datasets such as MNIST \cite{lecun_gradient-based_1998}, Caltech-256 \cite{griffin_caltech-256_2007}, and ImageNet \cite{deng_imagenet:_2009} allowing for common baselines to be introduced and allow for the introduction of transfer learning, allowing for the reuse of models trained in one task to be utilised for another \cite{pan_survey_2010}.

EXPAND!!!
Furthermore, additional regularisation techniques have provided improvements to model accuracy. Notable examples of this in literature which are now commonplace in deep learning models include dropout \cite{srivastava_dropout:_2014}, batch normalisation \cite{ioffe_batch_2015}, stochastic gradient descent with warm restarts \cite{loshchilov_sgdr:_2016}, mixup \cite{zhang_mixup:_2017}, as well as various forms of data augmentation. 

\section{Deep Learning for Computer Vision}\label{ch:Background,sec:DLforCV}

The field of computer vision is one area where deep learning has really excelled. Concepts such as CNNs have quickly become commonplace for solving computer vision tasks, in most cases replacing the need for specialised hand-crafted pipelines. The era of CNNs in computer vision started with LeNet \cite{lecun_gradient-based_1998}, which was developed to recognise hand written digits on cheques. Before this, character recognition had been achieved with hand engineered feature spaces which machine learning models would learn to classify. With LeNet, these hand engineered features were made redundant, as the CNN could learn the optimal representation of these features from the characters themselves. 

\subsection{Convolutional Neural Networks}\label{ch:Background,sec:CNN,sub:CNN}
Modern CNNs are composed of three main layer types; convolutional layers, pooling layers, and fully connected layers. Each of these layers will perform some operation on the input passed to it, and provide a transformed output to the subsequent layer(s). These layers can be stacked in various orientations to build different CNN architectures. Whilst this basic principle may seem simplistic, CNNs now form the basis of most computer vision research, being utilised in facial recognition, autonomous vehicles, and fine-grain visual categorisation. 

EXPAND THE LAYERS WITH MATHS
\subsubsection{Convolutional Layers}\label{ch:Background,sec:CNN,sub:CNN,subsub:convolution}
The convolutional layer is the workhorse of the CNN, performing the vast majority of the operations required. This layer will operate over the whole input image provided using a kernel, sliding over the image spatially computing dot products. These kernels usually start looking for low level features such as line groups first, working up to more complex shapes the deeper the layer is. This allows for one image to become of stack of filtered images, or feature maps. These feature maps show how much of the feature matches at each individual pixel location. 

\subsubsection{Pooling Layers}\label{ch:Background,sec:CNN,sub:CNN,subsubsec:pooling}
Pooling layers help reduce the computational complexity of the convolutions performed by the CNN. This is achieved by reducing the spatial dimensions of the input ready for the next convolutional layer. Note pooling only affects the width and height of the input, not the depth (an RGB colour scheme has a depth of 3). This reduction inevitably leads to a reduction in the amount of information available in the input; this is advantageous however as it leads to less computational complexity for subsequent layers aiding in the minimisation of overfitting in the model. A number of different pooling layer architectures exist in literature, such as max pooling, average pooling \cite{boureau_theoretical_2010}, and stochastic pooling \cite{zeiler_stochastic_2013}.

\subsubsection{Fully Connected Layers}\label{ch:Background,sec:CNN,sub:CNN,subsubsec:fullyConnected}
Fully connected layers, usually preceded by multiple convolutional and pooling layers in most architectures, are layers which each neuron has a connection to all other neurons in the previous layer. Thus, their activation function can be computed through a matrix multiplication with a bias weighting. These layers convert the list of feature maps into 1-d feature vectors, which can then either be considered a map in its own right for further processing \cite{krizhevsky_imagenet_2012} or as a category for classification as the last layer of the network \cite{girshick_rich_2014}. For example in a CNN which classifies either \texttt{x} or \texttt{y}, the final fully connected layer would have two neurons, one for each of the respective classifications. 

\subsubsection{Layer Architectures}\label{ch:Background,sec:CNN,sub:CNN,subsub:layerArchitecture}
Using the three layer types described above it is possible to create, in theory, an infinite number of CNN architectures all with different amounts and combinations of layers. There is no guarantee that every possible architecture will perform well however (indeed, one possible combination would be a single fully connected layer, which would not perform well at all). Whilst it may be advantageous for certain areas of research to create their own custom CNN architecture, mostly through trial and error, this is not applicable for most cases. For the vast majority of cases, there exists in literature well-defined generalised CNN architectures, and it is often these architectures which are utilised for the vast majority of computer vision tasks. 

As discussed previously in Section \ref{ch:Background,sec:DLforCV}, LeNet \cite{lecun_gradient-based_1998} was the first well defined CNN architecture. LeNet was only 7 layers deep, but performed well enough to be applied by some banks for automatic recognition of numbers on cheques. It wasn't until around 2012 that more attention was paid to these defined architectures however, thanks to AlexNet \cite{krizhevsky_imagenet_2012}. Utilising a similar but deeper architecture to LeNet, with more filters and a larger number of stacked convolutional layers. AlexNet also included now common CNN building blocks such as dropout \cite{srivastava_dropout:_2014}, max pooling \cite{boureau_theoretical_2010}, and ReLU activation functions. EXPAND ON RELU

 In 2014, Google introduced GoogleNet, also known as an Inception architecture, to the ILSVRC14 competition \cite{szegedy_going_2015}. This net achieved a top-5 error rate of 6.67\%, very close to what untrained humans could achieve on the competition dataset. This was achieved through a 22 layer deep CNN utilising several small convolutions, reducing the number of parameters from 60million in AlexNet to 4million in GoogleNet. 

Finally ResNet was introduced a year later at ILSVRC15. This architecture can be as large as 152 layers deep, and achieved a human-beating top-5 error rate of 3.57\% \cite{he_deep_2015}. Shallower versions of ResNet exist, such as ResNet50 and ResNet101, which are 50 and 101 layers deep respectively. 

\section{Object Detection Algorithms}\label{ch:Background,sec:objectDetection}
As discussed, CNNs are now one of the main tools available for computer vision tasks. Object detection tasks are no exception, with CNNs now being utilised en masse. These tasks concern themselves with attempting to identify and segment distinct classes of objects found in images and video, and is often performed in one of two ways. 

\subsection{Region Proposal Networks}\label{ch:Background,sec:objectDetection,sub:RPN}
The first, known as a Region Proposal Network (RPN), attempts to find image regions likely to contain objects of given classes. Training data is usually provided in the form of bounding boxes drawn around objects of interest and labelled with the corresponding class. These RPN detections can be relatively fast, using a selection search \cite{uijlings_selective_2013} gives around 2000 region proposals in only a few seconds on a CPU.

Selection search is most commonly used with the R-CNN object detection algorithm \cite{girshick_rich_2014}. This algorithm has a high recall rate due to the large amount of proposals, as there is a high probability that some of these proposals will contain Regions of Interest (ROIs) containing the objects being searched for. However, this can be time consuming and computationally expensive (although less computationally expensive than just sliding a window over the full image) as the network needs to be trained to classify these 2000 region proposals, taking up a large amount of disk space. Detection can also be slow using a vanilla R-CNN and, with the selection search being fixed, no adaptive learning takes place here which may lead to bad region proposals throughout. 

Some of these time drawbacks were fixed in later versions of R-CNN, known as Fast-RCNN \cite{girshick_fast_2015}. Rather than feeding the region proposals generated to the CNN, this algorithm instead feeds the input image to the CNN and generates a convolutional feature map. ROIs can then be taken from the feature map using selection search and warped into a shape suitable for the pooling layer, before being reshaped again into a fixed size for the fully connected layer. This is advantageous as it allows us to reuse some computations and allows for backpropagation to occur throughout the network, greatly improving runtimes.  This also means however that the runtime is dominated by how fast ROIs can be generated. 

To fix this issue, Faster-RCNN was developed \cite{ren_faster_2015}. Now, instead of utilising selection search to generate the ROIs we can utilise a separate network to predict ROIs which can then be used to classify images within the regions. With this, we now train with four losses; 
\begin{enumerate*}
	\item An object/not object classification from the RPN,
	\item The ROI shift,
	\item The object classification,
	\item Final bounding box co-ordinates.
\end{enumerate*}

\subsection{Detection Without Proposals}\label{ch:Background,sec:objectDetection,sub:noProposals}

One issue with all RPNs is that they generally take a significant amount of time in order to classify objects in images, with the bottleneck being the region proposal generation. Because of this, there are algorithms which attempt to remove the region proposals altogether and instead look at the whole image. This input image is divided into an equal size grid. Within each square of the grid, we take a set number of bounding boxes which the CNN provides classification confidences for. Any above a set threshold are used to locate the object within the image. These algorithms are essentially one large CNN rather than splitting into a CNN and an RPN and are thus much faster although are not as accurate, especially on smaller objects due to the spatial constraints of the algorithm. Examples of detection without proposal systems include YOLO \cite{redmon_you_2016} and SSD \cite{liu_ssd:_2016}. 

\section{Cetacean Object Detection}\label{ch:Background,sec:cetaceanDetection}

The idea of utilising statistical methodology and machine learning in a marine cetacean space has, in recent years, been gaining popularity, with multiple papers being published in this area. Karnowski \textit{et al.} propose using Robust PCA to subtract background from underwater images to help identify captive bottlenose dolphins, and track their movements through multiple distinct areas, allowing researchers to annotate pool positions 14 times faster than before \cite{karnowski_dolphin_2015}. Bouma \textit{et al.} provide a system focusing on metric embedding learning to photo-id individual common dolphins, achieving top-5 accuracy scores of around 93\% \cite{bouma_individual_2018}. Further, Qui\~{n}onez \textit{et al.} propose a CNN based system to detect four classes: \texttt{dolphin}, \texttt{dolphin\_pod}, \texttt{open\_sea}, and \texttt{seabirds} \cite{quinonez_using_2019}. It is thus clear from recent literature that there is great interest in speeding up the photo-id of cetaceans for tracking and conservation efforts. 

Outside of newer deep learning object detection, cetacean classification in the world of marine biology is already aided through software such as DARWIN \cite{stewman_iterative_2006} and Wildbook \cite{berger-wolf_wildbook:_2017-1}. These systems however require a large amount of human preprocessing and input which new deep learning systems would not require.

\section{Fine-Grained Visual Categorisation}\label{ch:Background,sec:Fine-grainedCV}

Whilst the world of coarse-grained visual categorisation has mostly been solved, research is now focusing on more fine-grained visual categorisation. Using this project as an example, the detection of dolphins in an image and classifying them at a coarse-grain level as \texttt{dolphin} is relatively easy with current computer vision systems, with the vast majority of work being setup and hyperparameter tuning. However, being able to finely classify these dolphins with individual identifiers is a much more difficult task, as is all other fine-grained categorisation tasks. 

\subsection{Fine-Grained Datasets}\label{ch:Background,sec:Fine-grainedCV,sub:FGDatasets}

One major issue with these tasks is the lack of available datasets. Unlike coarse-grained datasets such as ImageNet \cite{deng_imagenet:_2009}, these fine-grained datasets must be labelled by domain experts. As such, only a few of these datasets currently exist. The Caltech-UCSD Brids-200-2011 dataset (an updated version of the original Caltech-Birds-200 dataset \cite{welinder_caltech-ucsd_2010}) is a dataset of 200 different bird species \cite{wah_caltech-ucsd_2011}. Similarly, the Stanford Dogs dataset contains images of 120 different species of dog \cite{khosla_novel_2011}. Outside of animals, the Women's Fashion: Coats dataset details the diversity within women's clothing at a fine-grained level \cite{di_style_2013}. As can be seen, these datasets mainly focus on identification at a species level rather than an individual-within-a-species level like this project. This is the main motivation behind the creation of the Northumberland Dolphin Dataset as part of this project, as is detailed in Appendix.

\subsection{Part Segmentation}\label{ch:Background,sec:Fine-grainedCV,sub:PartSegmentation}
Whilst fine-grained visual categorisation is still an area of new research, one of the most common approaches to tackling these problems is through the use of part segmentation, whereby a coarse-grained classification is broken down into sub-components which are then analysed to provide a fine-grained identification \cite{zhang_part-based_2014}. How this is to be achieved is still being explored, with some research focusing on a form of hierarchical part matching \cite{xie_hierarchical_2013}, some on alignment of objects to define a super-class shape \cite{gavves_fine-grained_2013}, some utilising deformable part descriptors \cite{zhang_deformable_2013}, and others using part localisation \cite{liu_dog_2012}. This project hopes to utilise some form of part segmentation in order to identify individual cetaceans, most likely through scars, nicks, and dents. 


%%%%%%%%%%%%%%%%%%%
\nomenclature[z-CNN]{CNN}{Convolutional Neural Networks}
\nomenclature[z-CV]{CV}{Computer Vision}